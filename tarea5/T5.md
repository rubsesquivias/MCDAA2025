# TAREA5
- Investigar sobre algún otro algoritmo no supervisado que pueda usarse en tu código. Da un panorama sobre el modelo matemático que emplea y explica por qué conviene aplicarlo a tus datos. Algunos modelos que no se vieron en clase son Affinity Propagation, BIRCH, DBSCAN, Mean Shift, Nearest Neighbors, OPTICS, Spectral Clustering, TSNE, entre otros.
- Investigar otras estrategias para determinar número de grupos en estos algoritmos (como los índices de Calinski-Harabasz o de Davies-Bouldin), elegir la más adecuada al método que elegiste
- Aplicar al menos un algoritmo no supervisado a tus datos para encontrar estructuras subyacentes
- Elegir alguna métrica para determinar número de grupos, usarla y discutirla
- Busca alguna revista científica que publique trabajos relacionados con el tuyo
- Crea artículo mediante Latex con base en los lineamientos de la revista elegida y redacta ahí tus resultados, discusiones y bibliografía
- Sube el código de tu tarea, los archivos de Latex y el PDF del artículo en tu repositorio, claramente diferenciados

### Investigar sobre algún otro algoritmo no supervisado que pueda usarse en tu código. Da un panorama sobre el modelo matemático que emplea y explica por qué conviene aplicarlo a tus datos. Algunos modelos que no se vieron en clase son Affinity Propagation, BIRCH, DBSCAN, Mean Shift, Nearest Neighbors, OPTICS, Spectral Clustering, TSNE, entre otros.

**DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** es un algoritmo de aprendizaje no supervisado utilizado para identificar grupos (clusters) en datos que presentan estructuras de densidad variable. A diferencia de métodos como *K-Means*, DBSCAN no requiere especificar el número de grupos de antemano, sino que agrupa los puntos en función de la densidad local de los datos.

El modelo matemático de DBSCAN se basa en dos parámetros principales:

- **ε (epsilon)**: distancia máxima entre dos puntos para ser considerados vecinos.
- **minPts**: número mínimo de puntos necesarios para formar una región densa.

Un punto se clasifica como:
- **Núcleo (core point)** si tiene al menos `minPts` vecinos dentro del radio `ε`.
- **Borde (border point)** si está cerca de un punto núcleo, pero no cumple por sí mismo el requisito de densidad.
- **Ruido (noise point)** si no pertenece a ningún grupo.

Formalmente, el algoritmo identifica regiones densas según la relación de alcanzabilidad:  
Dos puntos `p` y `q` están conectados por densidad si existe una secuencia de puntos `p1, p2, ..., pn` tal que cada `pi` está dentro de la distancia `ε` del siguiente y todos son puntos núcleo.

DBSCAN resulta conveniente para este conjunto de datos de **películas** porque permite descubrir **agrupamientos naturales** sin imponer formas geométricas predeterminadas (como esferas o elipses). Esto es especialmente útil si los datos contienen ruido o si las variables (como duración, calificación o popularidad) no siguen una distribución homogénea. Además, el algoritmo puede detectar películas atípicas (outliers), lo que aporta información valiosa sobre producciones excepcionales o poco comunes.

### Investigar otras estrategias para determinar número de grupos en estos algoritmos (como los índices de Calinski-Harabasz o de Davies-Bouldin), elegir la más adecuada al método que elegiste

A diferencia de otros métodos como *K-Means*, el algoritmo **DBSCAN** no requiere definir explícitamente el número de grupos (*k*) antes de ejecutarse. En su lugar, el resultado depende de los parámetros de densidad `ε` (epsilon) y `minPts`. Sin embargo, existen métricas y estrategias que permiten evaluar la **calidad de la agrupación** obtenida y, de manera indirecta, estimar cuántos grupos son adecuados para el conjunto de datos.

Entre las métricas más utilizadas se encuentran:

- **Índice de Calinski–Harabasz (CH)**: mide la relación entre la dispersión inter-cluster (separación entre grupos) y la dispersión intra-cluster (cohesión interna). Un valor más alto del índice indica una mejor definición de los grupos.  
  \[
  CH = \frac{Tr(B_k)}{Tr(W_k)} \times \frac{N - k}{k - 1}
  \]
  donde \(Tr(B_k)\) representa la varianza entre grupos y \(Tr(W_k)\) la varianza dentro de los grupos.

- **Índice de Davies–Bouldin (DBI)**: evalúa la similitud promedio entre cada grupo y su grupo más parecido. Un valor más bajo indica mejor separación entre clusters.  
  \[
  DBI = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \frac{s_i + s_j}{d_{ij}}
  \]
  donde \(s_i\) es la dispersión del grupo \(i\) y \(d_{ij}\) la distancia entre los centroides de los grupos \(i\) y \(j\).

En el caso de **DBSCAN**, la métrica más adecuada suele ser el **índice de Davies–Bouldin**, ya que:
1. No requiere conocer el número real de clusters a priori.  
2. Tolera bien la presencia de ruido o puntos aislados.  
3. Permite comparar distintas configuraciones de `ε` y `minPts` para seleccionar la más coherente con la estructura de los datos.

En la práctica, se recomienda ejecutar DBSCAN con varios valores de `ε` y `minPts`, y calcular el índice **Davies–Bouldin** para cada resultado. El conjunto de parámetros que genere el **menor valor del índice** se considera el más apropiado, indicando una partición más clara y grupos mejor definidos.

Notebook vista en clase: https://colab.research.google.com/drive/1I_XijSMwoXU5SSH8172ga8GwBCGpvfmd?usp=sharing

* Mis archivos:
[Database Movies](./movies.csv)
[Notebook en Google colab](./tarea4.ipynb)