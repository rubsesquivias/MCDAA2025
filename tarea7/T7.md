# TAREA 7
- Redactar la Metodología del artículo, explicando los métodos usados con base en la literatura que los sustenta.

(Este mismo escrito se ha actualizado dentro de la plantilla en latex)

#  Metodología

Para este estudio se estructuraron distintas fases con el propósito de identificar patrones, estructuras y algunas cuantas relaciones predictivas posibles dentro de una base de datos de películas.  
El análisis se centró en variables numéricas como **calificación**, **popularidad**, **presupuesto** y **duración**, entre otras, buscando agrupar y modelar el comportamiento de las cintas mediante técnicas de *machine learning* supervisadas y no supervisadas.

### Preprocesamiento de datos

Primero, se realizó una limpieza general del conjunto de datos eliminando valores nulos y registros incompletos.  
Posteriormente, se aplicó una **normalización mediante estandarización**, con el fin de evitar que variables con escalas distintas influyeran de forma desigual en los algoritmos.

La estandarización se realiza con la siguiente fórmula:

$$
z = \frac{x - \mu}{\sigma}
$$

donde:  
- $$\( x )$$ = valor original de la variable 
- $$( \mu ) $$ = media de la variable 
- $$( \sigma ) $$ = desviación estándar

De esta manera, todas las variables quedaron con media 0 y desviación estándar 1, lo que garantiza la comparabilidad entre ellas.

### Agrupamiento con DBSCAN

Utilizando el algoritmo **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**, que forma grupos a partir de regiones densamente pobladas, separando las zonas de baja densidad como ruido se realiza el siguiente proceso.

Un punto \( p \) pertenece a un clúter si existe al menos un punto \( q \) tal que:

$$
dist(p, q) \leq \varepsilon
$$

y \( q \) tiene al menos *min_samples* vecinos dentro de ese radio.  
Los puntos que no cumplen esta condición se etiquetan como ruido (\( cluster = -1 \)).

Este enfoque resulta muy bueno para la base de datos de películas, ya que la distribución no sigue una forma geométrica regular y el algoritmo no requiere especificar el número de grupos como tal.

Tras esto, se exploraron distintas combinaciones de los parámetros **ε (eps)** y **min_samples** para obtener la mejor configuración posible.  La calidad de cada uno de los los agrupamientos se evaluó mediante el **índice de Davies–Bouldin (DBI)**:

$$
DBI = \frac{1}{k} \sum_{i=1}^{k} \max_{i \neq j} \left( \frac{s_i + s_j}{d_{ij}} \right)
$$

donde:  
- $$( s_i ):$$ dispersión promedio de los puntos del clúster \( i \) 
- $$( d_{ij} \): $$ distancia entre los centroides de los clústeres $$( i )$$ y $$( j )$$ 
- $$( k ): $$ número total de clústeres 

Cuanto menor es el DBI, mejor es la separación y cohesión entre los grupos.

### Modelos supervisados

Con el fin de extender el análisis y realizar predicciones sobre las características de las películas (por ejemplo, su calificación o nivel de popularidad), se incorporaron algoritmos de aprendizaje **supervisado** los cuales son:  
**Regresión Lineal** y **Random Forest**. Se parte a desglozar cada uno de estos.

#### Regresión Lineal

El modelo busca encontrar una relación lineal entre las variables predictoras $$( x_i )$$ y la variable respuesta $$( y )$$:

$$
\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_n x_n + \epsilon
$$

donde:  
- $$( \hat{y} ): $$ valor estimado de la variable dependiente 
- $$( \beta_i ): $$ coeficientes ajustados del modelo  
- $$( \epsilon\): $$ término de error 

Este modelo se utilizó para aproximar tendencias generales y evaluar cómo ciertos atributos influyen en el rendimiento o aceptación de las películas.

#### Random Forest

El algoritmo **Random Forest** está basado en el principio de *ensembles*, combinando múltiples árboles de decisión entrenados con subconjuntos aleatorios de los datos. Cada árbol genera una predicción, y el resultado final se obtiene mediante el **promedio** (para regresión) o **voto mayoritario** (para clasificación).

Matemáticamente, el modelo se expresa como:

$$
\hat{y} = \frac{1}{T} \sum_{t=1}^{T} f_t(x)
$$

donde $$\( f_t(x) \)$$ es la predicción del árbol $$( t )$$ y $$( T )$$ es el número total de árboles en el bosque.  
Este método reduce el sobreajuste (*overfitting*) y mejora la estabilidad de las predicciones.

### Evaluación de desempeño

Para evaluar los modelos supervisados, se consideraron métricas comunes de error como el **MAE (Mean Absolute Error)** y el **RMSE (Root Mean Square Error)**, definidos respectivamente como:

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$

Estas métricas cuantifican la diferencia promedio entre los valores reales y los predichos, permitiendo medir la precisión de los modelos utilizados.

### Bibliografía
- Delen, D., Sharda, R., & Kumar, P. (2007). Movie forecast guru: A Web-based DSS for Hollywood managers.
Decision Support Systems, 43(4), 1151–1170.
https://doi.org/10.1016/j.dss.2006.03.012
- Hastie, Tibshirani & Friedman (2009). *The Elements of Statistical Learning.*  
- Breiman, L. (2001). *Random Forests.* Machine Learning, 45(1).  
- James, Witten, Hastie & Tibshirani (2021). *An Introduction to Statistical Learning.*  
- Documentación de *scikit-learn*: [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)

* Mis archivos:

[Database Movies](./movies.csv)

[Artículo en PDF](./Articulo%20AA%20(tarea6).pdf)

[Artículo en overleaf](./Articulo%20AA%20(tarea6).zip)

Archivo de latex con el artículo actualizado al momento de esta tarea:
https://www.overleaf.com/3371275523dckzxdbqmrhg#47441d